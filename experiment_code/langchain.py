# -*- coding: utf-8 -*-
"""langchain.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17u8gV3zQHM4Hh8bJ2MD1MlRo7_yvuui1
"""

!pip install langchain
!pip install openai
!pip install langchain_community

from langchain.chat_models import ChatOpenAI
from langchain.prompts.chat import ChatPromptTemplate
from langchain.chains import SequentialChain, LLMChain

openai_api_key = "XXX"
# client = OpenAI(api_key=openai_api_key)

conversation="I don't smoke. I am Experiencing bad breath and swollen gums. It's annoying. I drink alcohol frequently"
patient_information="""
Age: 45 years old
Gender: Female
Symptoms: Experiencing bad breath and swollen gums
Allergy history: No allergy
Social habits: Non-smoker, occasional alcohol drinker
Lifestyle habits: Enjoys eating sweets, brushes teeth twice a day using a soft-bristled toothbrush
"""
dentist_question="I would switch to an electric toothbrush - try to reduce sugar intake as much as possible. How frequently do you have sweet things a day?"

llm_model = "gpt-3.5-turbo"

llm = ChatOpenAI(temperature=0.9, model=llm_model, openai_api_key=openai_api_key)
first_prompt = ChatPromptTemplate.from_template(
    """
    Based on the conversation context, use brief and precise statements to summarize the main content into the known_message.
    Conversation:
    ###
    {conversation}
    ###

    example: "experiencing bad breath, swollen gums, don't smoke, finds it annoying"

    Generate a summary message as known_message.
    """
)
# Chain 1: input=conversation, output=known_message
chain_one = LLMChain(llm=llm, prompt=first_prompt, output_key="known_message")

result = chain_one.run({"conversation": conversation})
print(result)

second_prompt = ChatPromptTemplate.from_template(
    """
    You are the patient who is going to see a dentist. And you are the stressful patient. You should answer in a stressful way.
    As the patient visiting a dentist, follow the scenario below to answer the dentist's question in a few sentences from the patient's perspective.
    When the dentist greets you, respond with a greeting and wait for their question.


    Example:
    Dentist: "How's your day going?"
    Patient: "I am not feeling well."

    The patient's conversation is what you need to generate.

    The information of you is:
    ###
    {patient_information}
    ###
    The message that you have already told dentist is:
    ###
    {known_message}
    ###
    The dentist's question is:
    ###
    {dentist_question}
    ###


    """
)
# chain 2
chain_two = LLMChain(llm=llm, prompt=second_prompt, output_key="answer")
# Create the SequentialChain
overall_chain = SequentialChain(
    chains=[chain_one, chain_two],
    input_variables=["conversation", "patient_information", "dentist_question"],
    output_variables=["known_message","answer"],
    verbose=True
)

input_data = {
    "conversation": conversation,
    "patient_information": patient_information,
    "dentist_question": dentist_question
}
results = overall_chain(input_data)


print(results.keys())
print(f"conversation: {results['conversation']}")
print(f"patient_information: {results['patient_information']} ")
print(f"known_message: {results['known_message']} ")

dentist_question_str = str({results['dentist_question']})
dentist_question_text = textwrap.fill(dentist_question_str, width=120)
print(f"dentist_question: {dentist_question_text} ")

answer_str = str({results['answer']})
answer_text = textwrap.fill(answer_str, width=120)
print(f"answer: {answer_text} ")

# Generate the patient conversation
# response = overall_chain.run({
#     "conversation": conversation,
#     "patient_information": patient_information,
#     "dentist_question": dentist_question
# })
# print(f'The overall chain is :{overall_chain}')
# print(f'The response is: {response}')

import textwrap
overall_chain_str = str(overall_chain)

# 设置所需的宽度，例如120个字符
wrapped_text = textwrap.fill(overall_chain_str, width=120)
print(f'The overall chain is:\n{wrapped_text}')